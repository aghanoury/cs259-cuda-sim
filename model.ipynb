{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tital V100 Model\n",
    "We'll define some system parameters and then define the model.\n",
    "\n",
    "This model, for simplicitys sake, could be broken down into three main inputs\n",
    "\n",
    "1. GPU parameters\n",
    "2. Convolutional Parameters\n",
    "3. \"CUDA\" parameters (i.e. how the Conv calculations are divided amongst cuda cores)\n",
    "\n",
    "Given the first 2 inputs, we should be able to define a roofline model. Given the 3rd input, we can then find the point at which our \"cuda\" implementation lies on said model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll define the parameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution model parameters\n",
    "\n",
    "# first layer is input, RGB image so that gives us three layers\n",
    "input_layers = {\n",
    "    'dimx': 226,\n",
    "    'dimy': 226,\n",
    "    'depth': 64,\n",
    "}\n",
    "\n",
    "kernel_parameters = {\n",
    "    \"x\": 5,\n",
    "    \"y\": 5,\n",
    "    \"depth\": input_layers[\"depth\"],\n",
    "    \"padding\": 3,\n",
    "    \"stridex\": 1,\n",
    "    \"stridey\": 1,\n",
    "}\n",
    "output_layers = {\n",
    "    'dimx': 226,\n",
    "    'dimy': 226,\n",
    "    'depth': 64,\n",
    "}\n",
    "\n",
    "# GPU parameters\n",
    "system_parameters = {\n",
    "    \"core_frequency\": 1.5e9,  # GHz\n",
    "    \"multiply\": 1,  # Ops per cycle\n",
    "    \"scratchpad_mem_access\": 1,  # Ops per cycle\n",
    "}\n",
    "\n",
    "# CUDA parameters\n",
    "cuda_parameters = {\n",
    "    \"tile_size\": 32,\n",
    "    \"block_size\": 32,\n",
    "    \"warp_size\": 32,\n",
    "    \"num_threads\": 1024,\n",
    "    \"num_blocks\": 1024,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll make some definitivitve calculations about our model. Total number of bytes and total operations. These should be constant regardless of how we allocate our problem space in CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bytes: 25.330078125 MB\n",
      "Total ops: 5.2301824 GFLOP\n"
     ]
    }
   ],
   "source": [
    "# the definitative total number of operations for this convolution.\n",
    "total_bytes = output_layers['dimx'] * output_layers['dimy'] * output_layers['depth'] * 4 # 4 bytes per float\n",
    "\n",
    "# every \n",
    "total_bytes += kernel_parameters['x'] * kernel_parameters['y'] * kernel_parameters['depth'] * output_layers['depth'] * 4 # 4 bytes per float\n",
    "total_bytes += input_layers['dimx'] * input_layers['dimy'] * input_layers['depth'] * 4 # 4 bytes per float\n",
    "\n",
    "# total_ops = input_layers['dimx'] * input_layers['dimy'] * input_layers['depth'] * kernel_parameters['x'] * kernel_parameters['y'] * kernel_parameters['depth']\n",
    "total_ops = output_layers['dimx'] * output_layers['dimy'] * output_layers['depth'] * kernel_parameters['x'] * kernel_parameters['y'] * kernel_parameters['depth']\n",
    "\n",
    "# print the total bytes in MB\n",
    "print(\"Total bytes: {} MB\".format(total_bytes / 1024 / 1024))\n",
    "\n",
    "# print the total ops in GFLOPS\n",
    "print(\"Total ops: {} GFLOP\".format(total_ops / 1000 / 1000 / 1000))\n",
    "\n",
    "# calculate ops per second"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our total number of operations and cores utilzed will give us roughly the total execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 81721600\n",
      "Bytes: 6400\n",
      "FLOPS/Byte: 12769.0\n",
      "Total FP32 cores: 5376\n",
      "Max theoretical throughput: 8064.0 GFLOPS\n",
      "Execution time: 0.0034050666666666667 seconds\n"
     ]
    }
   ],
   "source": [
    "streaming_multiprocessors = 84\n",
    "blocks_per_multiprocessor = 4\n",
    "fp32_cores_per_block = 16\n",
    "total_fp32_cores = streaming_multiprocessors * blocks_per_multiprocessor * fp32_cores_per_block\n",
    "\n",
    "\n",
    "flops = kernel_parameters['x'] * kernel_parameters['y'] * kernel_parameters['depth'] * output_layers['dimx'] * output_layers['dimy']\n",
    "bytes = kernel_parameters['x'] * kernel_parameters['y'] * kernel_parameters['depth'] * 4\n",
    "print(\"FLOPS: {}\".format(flops))\n",
    "print(\"Bytes: {}\".format(bytes))\n",
    "print(\"FLOPS/Byte: {}\".format(flops / bytes))\n",
    "\n",
    "print(\"Total FP32 cores: {}\".format(total_fp32_cores))\n",
    "\n",
    "max_theoretical_throughput = total_fp32_cores * system_parameters[\"core_frequency\"]\n",
    "print(\"Max theoretical throughput: {} GFLOPS\".format(max_theoretical_throughput / 1000 / 1000 / 1000))\n",
    "\n",
    "execution_time = total_ops / system_parameters[\"core_frequency\"] / cuda_parameters[\"tile_size\"] / cuda_parameters[\"block_size\"] \n",
    "print(\"Execution time: {} seconds\".format(execution_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
